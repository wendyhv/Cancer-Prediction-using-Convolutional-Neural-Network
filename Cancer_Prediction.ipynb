{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wendyhv/Cancer-Prediction-using-Convolutional-Neural-Network/blob/main/Cancer_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c5rRoKUWOsD",
        "outputId": "0f1340f0-0f42-4b73-dd7b-b426ce7b9bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.3)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage import io\n",
        "\n",
        "# Install pydicom package, which is used for handling DICOM files\n",
        "!pip install pydicom\n",
        "import pydicom\n",
        "import glob  # Used for file locations\n",
        "from PIL import Image  # Used for image processing\n",
        "from skimage.transform import resize  # Used for resizing images\n",
        "import copy  # Used for creating copies of objects\n",
        "import matplotlib.pyplot as plt  # Used for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLvr1AdSBezR",
        "outputId": "e9cf47d9-965e-4a85-e9db-c6ee1db35a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Import the drive module from the google.colab package\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7P2RlILwBxb"
      },
      "outputs": [],
      "source": [
        "# Set IPython to display all outputs from a cell (not just the last one)\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity=\"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4feyqxBVGpQJ"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdxdoauqj2zw"
      },
      "outputs": [],
      "source": [
        "# variable image path\n",
        "def image_processing_function(image_folder_path):\n",
        "    i=0\n",
        "    image_extension= \"*.dcm\"\n",
        "    image_files = glob.glob(image_folder_path+image_extension)\n",
        "    images = np.empty((len(image_files),512,512),dtype=np.int8)\n",
        "    for file in image_files:\n",
        "      dcm = pydicom.dcmread(file)\n",
        "      img = dcm.pixel_array.astype(np.int8)\n",
        "      if img.shape !=(512, 512):\n",
        "        print(dcm.filename)\n",
        "      max_value = img.max()\n",
        "      min_value = img.min()\n",
        "      if max_value != min_value:\n",
        "        img = (img - min_value) / ((max_value - min_value)*255)\n",
        "      else:\n",
        "        img = img * 0.0\n",
        "      images = np.append(images, img[np.newaxis,...],axis=0)\n",
        "      #images[i] = np.array(img)\n",
        "     # i+=1\n",
        "      #images[i] = np.stack([images,np.array(img)],axis=0)\n",
        "      #images = np.append(images, np.array(img))\n",
        "      #images = np.array(images)\n",
        "\n",
        "    # Convert the list of images into a numpy array\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-UCEC"
      ],
      "metadata": {
        "id": "YLZZzPCu__tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7hKM2B4mPwz",
        "outputId": "1b64fc1d-0590-4ca3-941b-1fcf34044475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c3dd485babe1>:15: RuntimeWarning: overflow encountered in byte_scalars\n",
            "  img = (img - min_value) / ((max_value - min_value)*255)\n"
          ]
        }
      ],
      "source": [
        "image_path1 =\"/content/drive/MyDrive/TCGA-UCEC/TCGA-D1-A174/\"\n",
        "image_path2 =\"/content/drive/MyDrive/TCGA-UCEC/TCGA-D1-A1NZ/\"\n",
        "image_path3 =\"/content/drive/MyDrive/TCGA-UCEC/TCGA-FI-A2F4/\"\n",
        "image_path4 =\"/content/drive/MyDrive/TCGA-UCEC/TCGA-D1-A160/\"\n",
        "image_path5 =\"/content/drive/MyDrive/TCGA-UCEC/TCGA-FI-A2D5/\"\n",
        "image_path6 =\"/content/drive/MyDrive/TCGA-UCEC/Non_genes/\"\n",
        "\n",
        "TCGA_D1_A174_images= image_processing_function(image_path1)\n",
        "TCGA_D1_A1NZ_images= image_processing_function(image_path2)\n",
        "TCGA_FI_A2F4_images= image_processing_function(image_path3)\n",
        "TCGA_D1_A160_images= image_processing_function(image_path4)\n",
        "TCGA_FI_A2D5_images= image_processing_function(image_path5)\n",
        "TCGA_Non_genes_images= image_processing_function(image_path6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9J1hYbrvrrX",
        "outputId": "6868b1b2-27b8-459e-ae83-130756390905"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "TCGA_D1_A174_images.shape\n",
        "TCGA_D1_A1NZ_images.shape\n",
        "TCGA_FI_A2F4_images.shape\n",
        "TCGA_D1_A160_images.shape\n",
        "TCGA_FI_A2D5_images.shape\n",
        "TCGA_Non_genes_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpVQY1iXulKO"
      },
      "outputs": [],
      "source": [
        "label_TCGA_D1_A174_images_LATS1 = np.full(TCGA_D1_A174_images.shape[0], 1) # Lats1\n",
        "label_TCGA_D1_A1NZ_images_LATS2 = np.full(TCGA_D1_A1NZ_images.shape[0], 2) # Lats2\n",
        "label_TCGA_FI_A2F4_images_MST1 = np.full(TCGA_FI_A2F4_images.shape[0], 3) # Mst1\n",
        "label_TCGA_D1_A160_images_YAP1 = np.full(TCGA_D1_A160_images.shape[0], 4) # Yap1\n",
        "label_TCGA_FI_A2D5_images_TAZ = np.full(TCGA_FI_A2D5_images.shape[0], 5)   # Taz\n",
        "label_TCGA_Non_genes_images = np.full(TCGA_Non_genes_images.shape[0], 0) # Non genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S2tlXYGCtRX"
      },
      "outputs": [],
      "source": [
        "merged_labels_LATS1 = np.concatenate((label_TCGA_D1_A174_images_LATS1,label_TCGA_Non_genes_images))\n",
        "merged_image_LATS1 = np.concatenate((TCGA_D1_A174_images,TCGA_Non_genes_images), axis=0)\n",
        "merged_labels_LATS2 = np.concatenate((label_TCGA_D1_A1NZ_images_LATS2,label_TCGA_Non_genes_images))\n",
        "merged_image_LATS2 = np.concatenate((TCGA_D1_A1NZ_images,TCGA_Non_genes_images), axis=0)\n",
        "merged_labels_MST1 = np.concatenate((label_TCGA_FI_A2F4_images_MST1,label_TCGA_Non_genes_images))\n",
        "merged_image_MST1 = np.concatenate((TCGA_FI_A2F4_images,TCGA_Non_genes_images), axis=0)\n",
        "merged_labels_YAP1 = np.concatenate((label_TCGA_D1_A160_images_YAP1,label_TCGA_Non_genes_images))\n",
        "merged_image_YAP1 = np.concatenate((TCGA_D1_A160_images,TCGA_Non_genes_images), axis=0)\n",
        "merged_labels_TAZ = np.concatenate((label_TCGA_FI_A2D5_images_TAZ,label_TCGA_Non_genes_images))\n",
        "merged_image_TAZ = np.concatenate((TCGA_FI_A2D5_images,TCGA_Non_genes_images), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfwdqN9W7GTp",
        "outputId": "082098a8-f93d-4967-ee24-51a2339895c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(706, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(708, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "merged_image_LATS1.shape\n",
        "merged_image_LATS2.shape\n",
        "merged_image_MST1.shape\n",
        "merged_image_YAP1.shape\n",
        "merged_image_TAZ.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-STAD"
      ],
      "metadata": {
        "id": "qthTxdtpAHU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J_Rmysh0EqL",
        "outputId": "21464c4b-94d9-452f-a44e-32bbf02aa094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c3dd485babe1>:15: RuntimeWarning: overflow encountered in byte_scalars\n",
            "  img = (img - min_value) / ((max_value - min_value)*255)\n"
          ]
        }
      ],
      "source": [
        "# image_path1 =\"/content/drive/MyDrive/TCGA-STAD/TCGA-VQ-AA6K/\"\n",
        "# image_path2 =\"/content/drive/MyDrive/TCGA-STAD/TCGA-VQ-A8E7/\"\n",
        "# image_path3 =\"/content/drive/MyDrive/TCGA-STAD/TCGA-VQ-A91D/\"\n",
        "# image_path4 =\"/content/drive/MyDrive/TCGA-STAD/TCGA-VQ-A8P2/\"\n",
        "# image_path5 =\"/content/drive/MyDrive/TCGA-STAD/Non_genes/\"\n",
        "\n",
        "# TCGA_VQ_AA6K_images= image_processing_function(image_path1)\n",
        "# TCGA_VQ_A8E7_images= image_processing_function(image_path2)\n",
        "# TCGA_VQ_A91D_images= image_processing_function(image_path3)\n",
        "# TCGA_VQ_A8P2_images= image_processing_function(image_path4)\n",
        "# TCGA_Non_genes_images= image_processing_function(image_path5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmCxPYSz0E2X",
        "outputId": "708f54dd-f7cf-4531-8a21-875a9b5adbde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# TCGA_VQ_AA6K_images.shape\n",
        "# TCGA_VQ_A8E7_images.shape\n",
        "# TCGA_VQ_A91D_images.shape\n",
        "# TCGA_VQ_A8P2_images.shape\n",
        "# TCGA_Non_genes_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU7hzzIP0G-_"
      },
      "outputs": [],
      "source": [
        "# label_TCGA_VQ_AA6K_images_LATS1 = np.full(TCGA_VQ_AA6K_images.shape[0], 1) # Lats1\n",
        "# label_TCGA_VQ_A8E7_images_LATS2 = np.full(TCGA_VQ_A8E7_images.shape[0], 2) # Lats2\n",
        "# label_TCGA_VQ_A91D_images_MST1 = np.full(TCGA_VQ_A91D_images.shape[0], 3) # Mst1\n",
        "# label_TCGA_VQ_A8P2_images_YAP1 = np.full(TCGA_VQ_A8P2_images.shape[0], 4) # Yap1\n",
        "# label_TCGA_Non_genes_images = np.full(TCGA_Non_genes_images.shape[0], 0) # Non genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnIBqha30HI4"
      },
      "outputs": [],
      "source": [
        "# merged_labels_LATS1 = np.concatenate((label_TCGA_VQ_AA6K_images_LATS1,label_TCGA_Non_genes_images))\n",
        "# merged_image_LATS1 = np.concatenate((TCGA_VQ_AA6K_images,TCGA_Non_genes_images), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0fCW1C70HSd",
        "outputId": "a71ab640-5705-47a7-b1b1-232affca56fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(708, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# merged_image_LATS1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-BLCA"
      ],
      "metadata": {
        "id": "h4PhT_SQAKqJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH5jzq0cVwLJ",
        "outputId": "f475ea94-4047-47f4-9f72-44a8e950ce2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c3dd485babe1>:15: RuntimeWarning: overflow encountered in byte_scalars\n",
            "  img = (img - min_value) / ((max_value - min_value)*255)\n"
          ]
        }
      ],
      "source": [
        "# image_path1 =\"/content/drive/MyDrive/TCGA-BLCA/TCGA-XF-AAN2/\"\n",
        "# image_path2 =\"/content/drive/MyDrive/TCGA-BLCA/TCGA-ZF-A9RD/\"\n",
        "# image_path3 =\"/content/drive/MyDrive/TCGA-BLCA/TCGA-XF-AAN0/\"\n",
        "# image_path4 =\"/content/drive/MyDrive/TCGA-BLCA/TCGA-FD-A3SO/\"\n",
        "# image_path5 =\"/content/drive/MyDrive/TCGA-BLCA/TCGA-XF-A9T3/\"\n",
        "# image_path6 =\"/content/drive/MyDrive/TCGA-BLCA/Non_genes/\"\n",
        "\n",
        "# TCGA_XF_AAN2_images= image_processing_function(image_path1)\n",
        "# TCGA_ZF_A9RD_images= image_processing_function(image_path2)\n",
        "# TCGA_XF_AAN0_images= image_processing_function(image_path3)\n",
        "# TCGA_FD_A3SO_images= image_processing_function(image_path4)\n",
        "# TCGA_XF_A9T3_images= image_processing_function(image_path5)\n",
        "# TCGA_Non_genes_images= image_processing_function(image_path6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS6ee73eVwYY",
        "outputId": "3148523e-2b4b-4b9d-ec39-cd7abe51a57b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# TCGA_XF_AAN2_images.shape\n",
        "# TCGA_ZF_A9RD_images.shape\n",
        "# TCGA_XF_AAN0_images.shape\n",
        "# TCGA_FD_A3SO_images.shape\n",
        "# TCGA_XF_A9T3_images.shape\n",
        "# TCGA_Non_genes_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVflHrs5Vwko"
      },
      "outputs": [],
      "source": [
        "# label_TCGA_XF_AAN2_images_LATS1 = np.full(TCGA_XF_AAN2_images.shape[0], 1) # Lats1\n",
        "# label_TCGA_ZF_A9RD_images_LATS2 = np.full(TCGA_ZF_A9RD_images.shape[0], 2) # Lats2\n",
        "# label_TCGA_XF_AAN0_images_MST1 = np.full(TCGA_XF_AAN0_images.shape[0], 3) # Mst1\n",
        "# label_TCGA_FD_A3SO_images_YAP1 = np.full(TCGA_FD_A3SO_images.shape[0], 4) # Yap1\n",
        "# label_TCGA_XF_A9T3_images_TAZ = np.full(TCGA_XF_A9T3_images.shape[0], 5)   # Taz\n",
        "# label_TCGA_Non_genes_images = np.full(TCGA_Non_genes_images.shape[0], 0) # Non genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t1qyxIaVww2"
      },
      "outputs": [],
      "source": [
        "# merged_labels_LATS1 = np.concatenate((label_TCGA_XF_AAN2_images_LATS1,label_TCGA_Non_genes_images))\n",
        "# merged_image_LATS1 = np.concatenate((TCGA_XF_AAN2_images,TCGA_Non_genes_images), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR28Dm8KVw82",
        "outputId": "2deaff6b-b59f-454c-8207-8a3134a7adac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# merged_image_LATS1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-OV"
      ],
      "metadata": {
        "id": "fDj6uE8oAV6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path1 =\"/content/drive/MyDrive/TCGA-OV/TCGA-30-1891/\"\n",
        "# image_path6 =\"/content/drive/MyDrive/TCGA-OV/Non_genes/\"\n",
        "\n",
        "# TCGA_30_1891_images= image_processing_function(image_path1)\n",
        "# TCGA_Non_genes_images= image_processing_function(image_path6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phh3PNwjnY3F",
        "outputId": "c9a0c1bd-4f23-4abc-b045-52f0b5254255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c3dd485babe1>:15: RuntimeWarning: overflow encountered in byte_scalars\n",
            "  img = (img - min_value) / ((max_value - min_value)*255)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TCGA_30_1891_images.shape\n",
        "# TCGA_Non_genes_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdzDUQPXnZCK",
        "outputId": "eb3b0733-b894-4042-912b-356acb6be09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(594, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label_TCGA_30_1891_images_LATS1 = np.full(TCGA_30_1891_images.shape[0], 1) # Lats1\n",
        "# label_TCGA_Non_genes_images = np.full(TCGA_Non_genes_images.shape[0], 0) # Non genes"
      ],
      "metadata": {
        "id": "GEwFRfzJnZJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_labels_LATS1 = np.concatenate((label_TCGA_30_1891_images_LATS1,label_TCGA_Non_genes_images))\n",
        "# merged_image_LATS1 = np.concatenate((TCGA_30_1891_images,TCGA_Non_genes_images), axis=0)"
      ],
      "metadata": {
        "id": "o0VhEY7tnZSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_image_LATS1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0BWTLenZcf",
        "outputId": "f1ab1d07-6e1c-4154-9402-fa3965f94f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(702, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-LUAD"
      ],
      "metadata": {
        "id": "j0zC5BUYAaTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path1 =\"/content/drive/MyDrive/TCGA-LUAD/TCGA-17-Z031/\"\n",
        "# image_path2 =\"/content/drive/MyDrive/TCGA-LUAD/TCGA-50-5044/\"\n",
        "# image_path4 =\"/content/drive/MyDrive/TCGA-LUAD/TCGA-50-5049/\"\n",
        "# image_path6 =\"/content/drive/MyDrive/TCGA-LUAD/Non_genes/\"\n",
        "\n",
        "# TCGA_17_Z031_images= image_processing_function(image_path1)\n",
        "# TCGA_50_5044_images= image_processing_function(image_path2)\n",
        "# TCGA_50_5049_images= image_processing_function(image_path4)\n",
        "# TCGA_Non_genes_images= image_processing_function(image_path6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjNoec--naC6",
        "outputId": "8a805668-58c4-480d-deca-53b205c710ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c3dd485babe1>:15: RuntimeWarning: overflow encountered in byte_scalars\n",
            "  img = (img - min_value) / ((max_value - min_value)*255)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TCGA_17_Z031_images.shape\n",
        "# TCGA_50_5044_images.shape\n",
        "# TCGA_50_5049_images.shape\n",
        "# TCGA_Non_genes_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9-p1UpnnaKx",
        "outputId": "af570c77-af34-47d9-e97a-65632be36be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(582, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label_TCGA_17_Z031_images_LATS1 = np.full(TCGA_17_Z031_images.shape[0], 1) # Lats1\n",
        "# label_TCGA_50_5044_images_LATS2 = np.full(TCGA_50_5044_images.shape[0], 2) # Lats2\n",
        "# label_TCGA_50_5049_images_YAP1 = np.full(TCGA_50_5049_images.shape[0], 4) # YAP1\n",
        "# label_TCGA_Non_genes_images = np.full(TCGA_Non_genes_images.shape[0], 0) # Non genes"
      ],
      "metadata": {
        "id": "RROimCuxnaSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_labels_LATS1 = np.concatenate((label_TCGA_17_Z031_images_LATS1,label_TCGA_Non_genes_images))\n",
        "# merged_image_LATS1 = np.concatenate((TCGA_17_Z031_images,TCGA_Non_genes_images), axis=0)"
      ],
      "metadata": {
        "id": "Msw43NtinaaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_image_LATS1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejIadyYdnah0",
        "outputId": "57367dd2-0f85-4683-9310-afe15904f04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(688, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-UCEC vs Other Cancers"
      ],
      "metadata": {
        "id": "Rm9rCj3YhAqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path1 =\"/content/drive/MyDrive/ LATS1-UCEC/\"\n",
        "# image_path6 =\"/content/drive/MyDrive/LATS1-Other cancers/\"\n",
        "\n",
        "# TCGA_LATS1_UCEC_images= image_processing_function(image_path1)\n",
        "# TCGA_LATS1_Other_Cancers_images= image_processing_function(image_path6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qodaR59TnasF",
        "outputId": "43004c75-38bd-4211-a5f9-7710a4780d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c3dd485babe1>:15: RuntimeWarning: overflow encountered in byte_scalars\n",
            "  img = (img - min_value) / ((max_value - min_value)*255)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TCGA_LATS1_UCEC_images.shape\n",
        "# TCGA_LATS1_Other_Cancers_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJSifUN4na0M",
        "outputId": "04d49c6f-ad28-4293-c96e-d63bed18f3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(688, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label_TCGA_LATS1_UCEC_images = np.full(TCGA_LATS1_UCEC_images.shape[0], 1) # LATS1 UCEC\n",
        "# label_TCGA_LATS1_Other_Cancers_images = np.full(TCGA_LATS1_Other_Cancers_images.shape[0], 0) # LATS1 Other cancers"
      ],
      "metadata": {
        "id": "PRnTSN-7na8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_labels_LATS1 = np.concatenate((label_TCGA_LATS1_UCEC_images,label_TCGA_LATS1_Other_Cancers_images))\n",
        "# merged_image_LATS1 = np.concatenate((TCGA_LATS1_UCEC_images,TCGA_LATS1_Other_Cancers_images), axis=0)"
      ],
      "metadata": {
        "id": "LR1_U_4TnbD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_image_LATS1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyJTXywcnbNr",
        "outputId": "5b0af193-75ee-43e8-8004-6d13f6cba0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(988, 512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN model"
      ],
      "metadata": {
        "id": "-Qqt-zc_Af96"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2knIX4s7jmq"
      },
      "outputs": [],
      "source": [
        "# Assuming your input images are stored in an array called 'images'\n",
        "batch_size = merged_image_LATS1.shape[0]\n",
        "height = merged_image_LATS1.shape[1]\n",
        "width = merged_image_LATS1.shape[2]\n",
        "\n",
        "# Add a channel dimension with size 1\n",
        "merged_image_LATS1 = np.reshape(merged_image_LATS1, (batch_size, height, width, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17BVEcEO1793"
      },
      "outputs": [],
      "source": [
        "# Import machine learning libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load the labeled images and labels arrays\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(merged_image_LATS1, merged_labels_LATS1, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X1_train.shape[1:]))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGoI-zZr7x2V",
        "outputId": "c31f68e1-222f-418f-915b-6c01d87c889b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "18/18 [==============================] - 24s 462ms/step - loss: 0.5512 - accuracy: 0.8830 - val_loss: 0.3714 - val_accuracy: 0.8732\n",
            "Epoch 2/4\n",
            "18/18 [==============================] - 4s 214ms/step - loss: 0.2484 - accuracy: 0.9202 - val_loss: 0.2091 - val_accuracy: 0.9296\n",
            "Epoch 3/4\n",
            "18/18 [==============================] - 4s 213ms/step - loss: 0.2244 - accuracy: 0.9238 - val_loss: 0.2089 - val_accuracy: 0.9296\n",
            "Epoch 4/4\n",
            "18/18 [==============================] - 4s 213ms/step - loss: 0.2228 - accuracy: 0.9238 - val_loss: 0.2316 - val_accuracy: 0.9296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e41d7ceddb0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 54ms/step - loss: 0.2316 - accuracy: 0.9296\n",
            "Test accuracy: 0.9295774698257446\n"
          ]
        }
      ],
      "source": [
        "# Train the model on the training data\n",
        "model.fit(X1_train, y1_train, epochs=4, validation_data=(X1_test, y1_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X1_test, y1_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chi-Square test"
      ],
      "metadata": {
        "id": "fvXIcUpwjJ1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your input images are stored in an array called 'images'\n",
        "batch_size1 = merged_image_LATS1.shape[0]\n",
        "height1 = merged_image_LATS1.shape[1]\n",
        "width1 = merged_image_LATS1.shape[2]\n",
        "batch_size2 = merged_image_LATS2.shape[0]\n",
        "height2 = merged_image_LATS2.shape[1]\n",
        "width2 = merged_image_LATS2.shape[2]\n",
        "\n",
        "# Add a channel dimension with size 1\n",
        "merged_image_LATS1 = np.reshape(merged_image_LATS1, (batch_size1, height1, width1, 1))\n",
        "merged_image_LATS2 = np.reshape(merged_image_LATS2, (batch_size2, height2, width2, 1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load the labeled images and labels arrays\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(merged_image_LATS1, merged_labels_LATS1, test_size=0.2, random_state=42)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(merged_image_LATS2, merged_labels_LATS2, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X1_train.shape[1:]))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X2_train.shape[1:]))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Fs8hpcUGUyBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency # Used for statistical testing in a contingency table\n",
        "\n",
        "# Convert images to categorical data\n",
        "X1_categorical = np.full(X1_test.shape[0], 1)\n",
        "X2_categorical = np.full(X2_test.shape[0], 0)\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = np.array([\n",
        "    [np.sum(X1_categorical == 1), np.sum(X2_categorical == 1)],\n",
        "    [np.sum(X1_categorical == 0), np.sum(X2_categorical == 0)]\n",
        "])\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi-Square Value:\", chi2)\n",
        "print(\"P-Value:\", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC1GPXEOUdjD",
        "outputId": "70ad3f83-1945-4937-e3ff-b14b8fd95c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Value: 280.01408450704224\n",
            "P-Value: 7.456360215413788e-63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "T test"
      ],
      "metadata": {
        "id": "OSf6OKOmAlVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from scipy import stats"
      ],
      "metadata": {
        "id": "4CqdJP_K_SB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-UCEC"
      ],
      "metadata": {
        "id": "rhhd8TBDmp7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the two-sample t-test\n",
        "# t_statistic, p_value = stats.ttest_ind(predicted_classes_LATS1, predicted_classes_LATS2)\n",
        "\n",
        "# Print the results\n",
        "# print(\"t-statistic:\", t_statistic)\n",
        "# print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndlXLarOSHD2",
        "outputId": "f831a412-93b4-4099-a927-a570bdd62a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-statistic: -0.20454770253238203\n",
            "p-value: 0.8380730695517762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your input images are stored in an array called 'images'\n",
        "# batch_size1 = merged_image_LATS1.shape[0]\n",
        "# height1 = merged_image_LATS1.shape[1]\n",
        "# width1 = merged_image_LATS1.shape[2]\n",
        "# batch_size2 = merged_image_LATS2.shape[0]\n",
        "# height2 = merged_image_LATS2.shape[1]\n",
        "# width2 = merged_image_LATS2.shape[2]\n",
        "# batch_size3 = merged_image_MST1.shape[0]\n",
        "# height3 = merged_image_MST1.shape[1]\n",
        "# width3 = merged_image_MST1.shape[2]\n",
        "# batch_size4 = merged_image_YAP1.shape[0]\n",
        "# height4 = merged_image_YAP1.shape[1]\n",
        "# width4 = merged_image_YAP1.shape[2]\n",
        "# batch_size5 = merged_image_TAZ.shape[0]\n",
        "# height5 = merged_image_TAZ.shape[1]\n",
        "# width5 = merged_image_TAZ.shape[2]\n",
        "\n",
        "# Add a channel dimension with size 1\n",
        "# merged_image_LATS1 = np.reshape(merged_image_LATS1, (batch_size1, height1, width1, 1))\n",
        "# merged_image_LATS2 = np.reshape(merged_image_LATS2, (batch_size2, height2, width2, 1))\n",
        "# merged_image_MST1 = np.reshape(merged_image_MST1, (batch_size3, height3, width3, 1))\n",
        "# merged_image_YAP1 = np.reshape(merged_image_YAP1, (batch_size4, height4, width4, 1))\n",
        "# merged_image_TAZ = np.reshape(merged_image_TAZ, (batch_size5, height5, width5, 1))"
      ],
      "metadata": {
        "id": "CDiIsVuCNKcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load the labeled images and labels arrays\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# X1_train, X1_test, y1_train, y1_test = train_test_split(merged_image_LATS1, merged_labels_LATS1, test_size=0.2, random_state=42)\n",
        "# X2_train, X2_test, y2_train, y2_test = train_test_split(merged_image_LATS2, merged_labels_LATS2, test_size=0.2, random_state=42)\n",
        "# X3_train, X3_test, y3_train, y3_test = train_test_split(merged_image_MST1, merged_labels_MST1, test_size=0.2, random_state=42)\n",
        "# X4_train, X4_test, y4_train, y4_test = train_test_split(merged_image_YAP1, merged_labels_YAP1, test_size=0.2, random_state=42)\n",
        "# X5_train, X5_test, y5_train, y5_test = train_test_split(merged_image_TAZ, merged_labels_TAZ, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model architecture\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X1_train.shape[1:]))\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X2_train.shape[1:]))\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X3_train.shape[1:]))\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X4_train.shape[1:]))\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X5_train.shape[1:]))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7U11MvjfNKew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data of each group\n",
        "# model.fit(X1_train, y1_train, epochs=4, validation_data=(X1_test, y1_test))\n",
        "# model.fit(X2_train, y2_train, epochs=4, validation_data=(X2_test, y2_test))\n",
        "# model.fit(X3_train, y3_train, epochs=4, validation_data=(X3_test, y3_test))\n",
        "# model.fit(X4_train, y4_train, epochs=4, validation_data=(X4_test, y4_test))\n",
        "# model.fit(X5_train, y5_train, epochs=4, validation_data=(X5_test, y5_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S74IvESLNKhU",
        "outputId": "5cf2e5f3-1c59-4bc9-f065-046166d4479e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "18/18 [==============================] - 78s 2s/step - loss: 0.5810 - accuracy: 0.8369 - val_loss: 0.5025 - val_accuracy: 0.8028\n",
            "Epoch 2/4\n",
            "18/18 [==============================] - 17s 920ms/step - loss: 0.4309 - accuracy: 0.8617 - val_loss: 0.5024 - val_accuracy: 0.8028\n",
            "Epoch 3/4\n",
            "18/18 [==============================] - 17s 936ms/step - loss: 0.3888 - accuracy: 0.8617 - val_loss: 0.3904 - val_accuracy: 0.8028\n",
            "Epoch 4/4\n",
            "18/18 [==============================] - 17s 939ms/step - loss: 0.2262 - accuracy: 0.9184 - val_loss: 0.2166 - val_accuracy: 0.9296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe381a78b0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "18/18 [==============================] - 36s 2s/step - loss: 12.6380 - accuracy: 0.8481 - val_loss: 0.5295 - val_accuracy: 0.8099\n",
            "Epoch 2/4\n",
            "18/18 [==============================] - 17s 952ms/step - loss: 0.3643 - accuracy: 0.8746 - val_loss: 0.4253 - val_accuracy: 0.8592\n",
            "Epoch 3/4\n",
            "18/18 [==============================] - 17s 953ms/step - loss: 0.2257 - accuracy: 0.9170 - val_loss: 0.1949 - val_accuracy: 0.9366\n",
            "Epoch 4/4\n",
            "18/18 [==============================] - 17s 941ms/step - loss: 0.2238 - accuracy: 0.9205 - val_loss: 0.1964 - val_accuracy: 0.9366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe1ff93dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "18/18 [==============================] - 37s 2s/step - loss: nan - accuracy: 0.8663 - val_loss: nan - val_accuracy: 0.8085\n",
            "Epoch 2/4\n",
            "18/18 [==============================] - 16s 910ms/step - loss: nan - accuracy: 0.8663 - val_loss: nan - val_accuracy: 0.8085\n",
            "Epoch 3/4\n",
            "18/18 [==============================] - 16s 912ms/step - loss: nan - accuracy: 0.8663 - val_loss: nan - val_accuracy: 0.8085\n",
            "Epoch 4/4\n",
            "18/18 [==============================] - 16s 916ms/step - loss: nan - accuracy: 0.8663 - val_loss: nan - val_accuracy: 0.8085\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe1ffe21d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "18/18 [==============================] - 34s 2s/step - loss: nan - accuracy: 0.8632 - val_loss: nan - val_accuracy: 0.8085\n",
            "Epoch 2/4\n",
            "18/18 [==============================] - 17s 925ms/step - loss: nan - accuracy: 0.8632 - val_loss: nan - val_accuracy: 0.8085\n",
            "Epoch 3/4\n",
            "18/18 [==============================] - 17s 925ms/step - loss: nan - accuracy: 0.8632 - val_loss: nan - val_accuracy: 0.8085\n",
            "Epoch 4/4\n",
            "18/18 [==============================] - 17s 925ms/step - loss: nan - accuracy: 0.8632 - val_loss: nan - val_accuracy: 0.8085\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe1ff93d90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "18/18 [==============================] - 36s 2s/step - loss: nan - accuracy: 0.8661 - val_loss: nan - val_accuracy: 0.8214\n",
            "Epoch 2/4\n",
            "18/18 [==============================] - 17s 923ms/step - loss: nan - accuracy: 0.8661 - val_loss: nan - val_accuracy: 0.8214\n",
            "Epoch 3/4\n",
            "18/18 [==============================] - 17s 923ms/step - loss: nan - accuracy: 0.8661 - val_loss: nan - val_accuracy: 0.8214\n",
            "Epoch 4/4\n",
            "18/18 [==============================] - 17s 925ms/step - loss: nan - accuracy: 0.8661 - val_loss: nan - val_accuracy: 0.8214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efdf5b21ae0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing data of each group\n",
        "# loss_LATS1, accuracy_LATS1 = model.evaluate(X1_test, y1_test)\n",
        "# loss_LATS2, accuracy_LATS2 = model.evaluate(X2_test, y2_test)\n",
        "# loss_MST1, accuracy_MST1 = model.evaluate(X3_test, y3_test)\n",
        "# loss_YAP1, accuracy_YAP1 = model.evaluate(X4_test, y4_test)\n",
        "# loss_TAZ, accuracy_TAZ = model.evaluate(X5_test, y5_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCAbvn9hNKnU",
        "outputId": "2432582d-4525-44b6-e861-4ae2f8cb5cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 166ms/step - loss: nan - accuracy: 0.8028\n",
            "5/5 [==============================] - 1s 167ms/step - loss: nan - accuracy: 0.8099\n",
            "5/5 [==============================] - 1s 165ms/step - loss: nan - accuracy: 0.8085\n",
            "5/5 [==============================] - 1s 165ms/step - loss: nan - accuracy: 0.8085\n",
            "5/5 [==============================] - 1s 165ms/step - loss: nan - accuracy: 0.8214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anova"
      ],
      "metadata": {
        "id": "ShI2ZxKtp7NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from scipy.stats import f_oneway"
      ],
      "metadata": {
        "id": "xjGHRRZKNAAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TCGA-UCEC"
      ],
      "metadata": {
        "id": "8Y9apxbAsUZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap scalar values in lists\n",
        "# evaluation_metrics_LATS1 = [accuracy_LATS1]\n",
        "# evaluation_metrics_LATS2 = [accuracy_LATS2]\n",
        "# evaluation_metrics_MST1 = [accuracy_MST1]\n",
        "# evaluation_metrics_YAP1 = [accuracy_YAP1]\n",
        "# evaluation_metrics_TAZ = [accuracy_TAZ]"
      ],
      "metadata": {
        "id": "Z0oELawzcKuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform ANOVA to compare the performance among the groups\n",
        "# f_statistic, p_value = f_oneway(\n",
        "    evaluation_metrics_LATS1,\n",
        "    evaluation_metrics_LATS2,\n",
        "    evaluation_metrics_MST1,\n",
        "    evaluation_metrics_YAP1,\n",
        "    evaluation_metrics_TAZ\n",
        ")\n",
        "\n",
        "# Print the results\n",
        "# print(\"F-statistic:\", f_statistic)\n",
        "# print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6nte8vHLCf8",
        "outputId": "10387908-3411-4220-d27f-985eff45dd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: nan\n",
            "p-value: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oYm6Om8Sspo"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}